{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17fc2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from cmf_engine.credentials import *\n",
    "from cmf_engine.fetch_data import *\n",
    "from cmf_engine.transform import *\n",
    "from cmf_engine.infer import *\n",
    "from cmf_engine.postprocess import *\n",
    "from cmf_engine.model_selection import *\n",
    "\n",
    "MODEL_PATH = os.path.abspath(\"./bin/model/\")\n",
    "# from cmf_engine.fetch_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf394f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------  Counter:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:66: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  c4c_df = pd.read_sql(c4c_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:67: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gac_df = pd.read_sql(gac_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:68: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  hfm_df = pd.read_sql(hfm_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  c4c_df = c4c_df.append(c4c_global[c4c_df.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_wochina = gac_df_wochina.append(gac_df_wochina_global[gac_df_wochina.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:112: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_all = gac_df_all.append(gac_df_all_global[gac_df_all.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_cm = hfm_df_cm.append(hfm_df_cm_global[hfm_df_cm.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_rev = hfm_df_rev.append(hfm_df_rev_global[hfm_df_rev.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:158: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  oil_df = oil_df.groupby([\"quarter\"])[\"BC_OIL_PRICE_USD\",\"WTI_OIL_PRICE_USD\"].mean().reset_index()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh_date: 2022Q1\n",
      "path---- C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\bin\\model\\rev\\RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  3.85it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.27it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['quarter']=X.index\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.forecast_start_date: 2022Q1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  3.41it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.78it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\postprocess.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_model_df = multi_model_df.append(data_dict[columns_out])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIA-DAI\n",
      "---------  Counter:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:66: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  c4c_df = pd.read_sql(c4c_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:67: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gac_df = pd.read_sql(gac_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:68: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  hfm_df = pd.read_sql(hfm_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  c4c_df = c4c_df.append(c4c_global[c4c_df.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_wochina = gac_df_wochina.append(gac_df_wochina_global[gac_df_wochina.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:112: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_all = gac_df_all.append(gac_df_all_global[gac_df_all.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_cm = hfm_df_cm.append(hfm_df_cm_global[hfm_df_cm.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_rev = hfm_df_rev.append(hfm_df_rev_global[hfm_df_rev.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:158: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  oil_df = oil_df.groupby([\"quarter\"])[\"BC_OIL_PRICE_USD\",\"WTI_OIL_PRICE_USD\"].mean().reset_index()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh_date: 2022Q2\n",
      "path---- C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\bin\\model\\rev\\RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  4.37it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.37it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['quarter']=X.index\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.forecast_start_date: 2022Q2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  3.58it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.78it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\postprocess.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_model_df = multi_model_df.append(data_dict[columns_out])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\model_selection.py:66: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\model_selection.py:66: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIA-DAI\n",
      "MENA-WEC\n",
      "---------  Counter:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:66: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  c4c_df = pd.read_sql(c4c_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:67: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gac_df = pd.read_sql(gac_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:68: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  hfm_df = pd.read_sql(hfm_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  c4c_df = c4c_df.append(c4c_global[c4c_df.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_wochina = gac_df_wochina.append(gac_df_wochina_global[gac_df_wochina.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:112: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_all = gac_df_all.append(gac_df_all_global[gac_df_all.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_cm = hfm_df_cm.append(hfm_df_cm_global[hfm_df_cm.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_rev = hfm_df_rev.append(hfm_df_rev_global[hfm_df_rev.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:158: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  oil_df = oil_df.groupby([\"quarter\"])[\"BC_OIL_PRICE_USD\",\"WTI_OIL_PRICE_USD\"].mean().reset_index()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh_date: 2022Q3\n",
      "path---- C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\bin\\model\\rev\\RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  3.40it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.77it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['quarter']=X.index\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.forecast_start_date: 2022Q3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  3.45it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.89it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\postprocess.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_model_df = multi_model_df.append(data_dict[columns_out])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\model_selection.py:66: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\model_selection.py:66: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIA-DAI\n",
      "MENA-WEC\n",
      "---------  Counter:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:66: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  c4c_df = pd.read_sql(c4c_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:67: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gac_df = pd.read_sql(gac_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:68: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  hfm_df = pd.read_sql(hfm_query,self.cnx)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  c4c_df = c4c_df.append(c4c_global[c4c_df.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_wochina = gac_df_wochina.append(gac_df_wochina_global[gac_df_wochina.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:112: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gac_df_all = gac_df_all.append(gac_df_all_global[gac_df_all.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:129: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_cm = hfm_df_cm.append(hfm_df_cm_global[hfm_df_cm.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:137: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hfm_df_rev = hfm_df_rev.append(hfm_df_rev_global[hfm_df_rev.columns])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\fetch_data.py:158: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  oil_df = oil_df.groupby([\"quarter\"])[\"BC_OIL_PRICE_USD\",\"WTI_OIL_PRICE_USD\"].mean().reset_index()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh_date: 2022Q4\n",
      "path---- C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\bin\\model\\rev\\RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  3.31it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.69it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['quarter']=X.index\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:282: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  chip = chip.append(div_infer_df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\transform.py:290: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  adj_infer_df = adj_infer_df.append(chip[['quarter', \"SL BASIN (CODE)\" ,'rev',\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.forecast_start_date: 2022Q4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:00<00:00,  3.23it/s]WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"days_elapsed\"] = days_before_recent_date\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_train[\"weight\"]=0.5\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\infer.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X=X_train,y=yt_train)#,sample_weight = weights)\n",
      "\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_before_recent_date: Int64Index([1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096, 1096,\n",
      "            ...\n",
      "               0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "           dtype='int64', length=326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.35it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\AppData\\Local\\Temp\\ipykernel_23848\\612050094.py:284: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  baseline_data_dict = baseline_data_dict.append(df)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Basin --> ASIA-DAI\n",
      "Predicting Basin --> MENA-WEC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\postprocess.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  multi_model_df = multi_model_df.append(data_dict[columns_out])\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\model_selection.py:66: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bgondaliya\\git\\cmf-mvp3-quarter\\cmf_engine\\model_selection.py:66: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIA-DAI\n",
      "MENA-WEC\n"
     ]
    }
   ],
   "source": [
    "def main(counter,dff):\n",
    "    print(\"---------  Counter: \", counter)\n",
    "    path = 'C:/Users/bgondaliya/git/cmf-mvp3-quarter/bin/local/'\n",
    "    \n",
    "    # 0. get pond Credentials\n",
    "    cred = credentials(path)\n",
    "    cxn_ODS,cxn_6438 = cred.read_cred()\n",
    "    \n",
    "    # 1. to get the data\n",
    "    data = TeleportData(cxn_6438,cxn_ODS)\n",
    "    raw_df = data.get_data()\n",
    "    oil_df = data.get_eia_data(cxn_ODS)\n",
    "#     raw_df.to_csv('raw_df.csv')\n",
    "#     oil_df.to_csv('oil_df.csv')\n",
    "    \n",
    "    # 2.define variables\n",
    "    basins = ['AML', 'ASIA', 'MENA', 'OAT', 'RCA', 'Worldwide']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data_start_date = \"2017-01-01\"\n",
    "    pickup_date = pd.to_datetime(\"2022-02-01\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3)#str(datetime.date(date.today().year, date.today().month, 1))\n",
    "    quarter = (pickup_date.month - 1) // 3 + 1\n",
    "    forecast_start_date = pickup_date.strftime('%YQ{}'.format(quarter))\n",
    "    refresh_date =  pd.to_datetime(\"2022-02-16\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3) #str(date.today())\n",
    "    refresh_date = refresh_date.strftime('%YQ{}'.format(quarter))\n",
    "    duration_of_forecast = 4 #quarter\n",
    "\n",
    "\n",
    "    print(\"refresh_date:\",refresh_date)\n",
    "#     data_start_date = \"2020-05-01\"\n",
    "#     forecast_start_date = str(pd.to_datetime(\"2022-03-01\",format=\"%Y-%m-%d\")+ relativedelta(months=counter))#str(datetime.date(date.today().year, date.today().month, 1))\n",
    "#     refresh_date =  str(pd.to_datetime(\"2022-03-26\",format=\"%Y-%m-%d\")+ relativedelta(months=counter)) #str(date.today())\n",
    "#     duration_of_forecast = 12\n",
    "    \n",
    "    \n",
    "    raw_df = raw_df[raw_df[\"SL BASIN (CODE)\"]!=\"SL_Elims\"]\n",
    "    raw_df[\"SL BASIN (CODE)\"] = raw_df[\"SL BASIN (CODE)\"]+\"-\"+raw_df[\"SL DIVISION (CODE)\"]\n",
    "\n",
    "\n",
    "    # Dep Vars\n",
    "    rev_var = [\"rev\"]\n",
    "    cm_var = ['cm']\n",
    "\n",
    "    # Baseline Model\n",
    "\n",
    "    rev_features = ['c4c_rev', 'gac_rev',\n",
    "           'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', 'gac_activity(t-1)',\n",
    "           'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "           'gac_activity(t+2)',\n",
    "           'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "           'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "           'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "           'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "           'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)']\n",
    "\n",
    "\n",
    "\n",
    "    cm_features = [\n",
    "            'rev', 'c4c_rev', 'gac_rev',\n",
    "           'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', 'gac_activity(t-1)',\n",
    "           'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "           'gac_activity(t+2)',\n",
    "           'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "           'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "           'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "           'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "           'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "           'rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)']\n",
    "\n",
    "    # Prophet Model\n",
    "    pr_rev_features = ['c4c_rev', 'gac_rev',\n",
    "           'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD',\n",
    "            'gac_activity(t-1)',\n",
    "           'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "           'gac_activity(t+2)',\n",
    "           'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "           'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "           'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "           'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "           'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "                    ]\n",
    "    \n",
    "    pr_cm_features = ['c4c_rev', 'gac_rev','rev',\n",
    "           'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', \n",
    "            'gac_activity(t-1)',\n",
    "           'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "           'gac_activity(t+2)', \n",
    "           'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "           'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "           'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "           'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "           'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "           'rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)',]\n",
    "    \n",
    "\n",
    "    # Neural Prophet Model\n",
    "\n",
    "    npr_features = ['c4c_rev', 'gac_rev',\n",
    "           'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', \n",
    "            'gac_activity(t-1)',\n",
    "           'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "           'gac_activity(t+2)', \n",
    "           'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "           'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "           'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "           'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "           'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',]\n",
    "\n",
    "\n",
    "    lagged_features = ['rev','rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)']\n",
    "\n",
    "\n",
    "    basins = ['AML-DAI',\n",
    "     'AML-MSP',\n",
    "     'AML-N/A',\n",
    "     'AML-NEO',\n",
    "     'AML-OTH',\n",
    "     'AML-PRS',\n",
    "     'AML-RPF',\n",
    "     'AML-WEC',\n",
    "     'ASIA-DAI',\n",
    "     'ASIA-MSP',\n",
    "     'ASIA-N/A',\n",
    "     'ASIA-NEO',\n",
    "     'ASIA-OTH',\n",
    "     'ASIA-PRS',\n",
    "     'ASIA-RPF',\n",
    "     'ASIA-WEC',\n",
    "     'GHQ-DAI',\n",
    "     'GHQ-MSP',\n",
    "     'GHQ-NEO',\n",
    "     'GHQ-OTH',\n",
    "     'GHQ-PRS',\n",
    "     'GHQ-RPF',\n",
    "     'GHQ-WEC',\n",
    "     'MENA-DAI',\n",
    "     'MENA-MSP',\n",
    "     'MENA-N/A',\n",
    "     'MENA-NEO',\n",
    "     'MENA-OTH',\n",
    "     'MENA-PRS',\n",
    "     'MENA-RPF',\n",
    "     'MENA-WEC',\n",
    "     'N/A-DAI',\n",
    "     'OAT-DAI',\n",
    "     'OAT-MSP',\n",
    "     'OAT-N/A',\n",
    "     'OAT-NEO',\n",
    "     'OAT-OTH',\n",
    "     'OAT-PRS',\n",
    "     'OAT-RPF',\n",
    "     'OAT-WEC',\n",
    "     'RCA-DAI',\n",
    "     'RCA-MSP',\n",
    "     'RCA-OTH',\n",
    "     'RCA-PRS',\n",
    "     'RCA-RPF',\n",
    "     'RCA-WEC',\n",
    "     'Worldwide-DAI',\n",
    "     'Worldwide-MSP',\n",
    "     'Worldwide-N/A',\n",
    "     'Worldwide-NEO',\n",
    "     'Worldwide-OTH',\n",
    "     'Worldwide-PRS',\n",
    "     'Worldwide-RPF',\n",
    "     'Worldwide-WEC'\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    # 3. transform the data for Rev\n",
    "    ## RF\n",
    "    tt = TrainingTransformer(data_start_date,duration_of_forecast,basins)\n",
    "    \n",
    "    \n",
    "    tt.fit(raw_df)\n",
    "    \n",
    "    train_df = tt.transform(raw_df,oil_df)\n",
    "    \n",
    "    train_df = train_df[train_df.index<forecast_start_date]\n",
    "    pr_train_df = train_df.copy()\n",
    "    pr_train_df = pr_train_df.reset_index()\n",
    "\n",
    "    it = InferenceRevTransformer(duration_of_forecast,pickup_date,basins)\n",
    "    it.fit(raw_df)\n",
    "    infer_df = it.transform(raw_df,oil_df)\n",
    "    infer_df.to_csv(\"infer_df.csv\")\n",
    "    pr_infer_df = infer_df.copy()\n",
    "    pr_infer_df = pr_infer_df.reset_index()\n",
    "\n",
    "    npr_train_df = pr_train_df.copy()\n",
    "    npr_infer_df = pr_infer_df.copy()\n",
    "    npr_infer_df.to_csv(\"npr_infer_df.csv\")\n",
    "\n",
    "    train_basins = set([\n",
    "         'MENA-WEC',\n",
    "         'ASIA-DAI',\n",
    "#          'OAT-RPF',\n",
    "#          'AML-WEC',\n",
    "#          'AML-DAI',\n",
    "#          'RCA-WEC',\n",
    "#          'OAT-WEC',\n",
    "#          'ASIA-RPF',\n",
    "#          'ASIA-PRS',\n",
    "#          'ASIA-WEC',\n",
    "#          'RCA-RPF',\n",
    "#          'RCA-DAI',\n",
    "#          'AML-PRS',\n",
    "#          'AML-RPF',\n",
    "#          'OAT-PRS',\n",
    "#          'MENA-PRS',\n",
    "#          'OAT-DAI',\n",
    "#          'MENA-RPF',\n",
    "#          'RCA-PRS',\n",
    "#          'MENA-DAI',\n",
    "#         'Worldwide-DAI','Worldwide-WEC','Worldwide-PRS','Worldwide-RPF'\n",
    "    ])\n",
    "\n",
    "    # Part-3\n",
    "    ### RF Model\n",
    "    rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"RF\")\n",
    "    print('path----',rev_model_path)\n",
    "    rev_trainer = RfModel(rev_features,rev_var,train_basins,pickup_date,rev_model_path)\n",
    "    rev_trainer.train(train_df)\n",
    "    rev_data_dict = rev_trainer.infer(infer_df)\n",
    "\n",
    "\n",
    "#     pr_rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"Prophet\")\n",
    "#     pr_rev_trainer = ProphetModel(pr_rev_features,pr_rev_features,rev_var,train_basins,pickup_date,pr_rev_model_path)\n",
    "#     pr_rev_trainer.train(pr_train_df)\n",
    "#     pr_rev_data_dict = pr_rev_trainer.infer(pr_infer_df)\n",
    "\n",
    "\n",
    "#     npr_rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"NeuralPr\")\n",
    "#     npr_rev_trainer = NeuralProphetModel(npr_features,npr_features,rev_var[0],[],\n",
    "#                                          train_basins,pickup_date,rev_model_path)\n",
    "#     npr_train = npr_rev_trainer.train(npr_train_df)\n",
    "#     npr_rev_data_dict = npr_rev_trainer.infer(npr_infer_df, npr_train)\n",
    "\n",
    "    \n",
    "    ## 4. \n",
    "    pickup_date2 = pd.to_datetime(pickup_date)+ relativedelta(months=-12)\n",
    "\n",
    "    it = InferenceRevTransformer(duration_of_forecast+4,pickup_date2,basins)\n",
    "    it.fit(raw_df)\n",
    "    infer_df = it.transform(raw_df,oil_df)\n",
    "\n",
    "    # 5. Preprocess CM data\n",
    "    ict = InferenceConMarTrTransformer(rev_data_dict, forecast_start_date)\n",
    "    ict.fit(infer_df)\n",
    "    cmf_infer_df = ict.transform(infer_df)    \n",
    "    cmf_infer_df.to_csv('cmf_infer_df.csv')\n",
    "\n",
    "    \n",
    "    # 5.1 \n",
    "\n",
    "#     icp = InferenceConMarPrTransformer(pr_rev_data_dict,train_basins, forecast_start_date)\n",
    "#     icp.fit(pr_infer_df)\n",
    "#     pr_cmf_infer_df = icp.transform(infer_df)\n",
    "\n",
    "#     icnp = InferenceConMarPrTransformer(npr_rev_data_dict,train_basins,forecast_start_date)\n",
    "#     icnp.fit(npr_infer_df)\n",
    "#     npr_cmf_infer_df = icnp.transform(infer_df)\n",
    "# 5.2\n",
    "#     npr_cm_model_path = os.path.join(MODEL_PATH, \"cm\", \"NeuralPr\")\n",
    "#     npr_cm_trainer = NeuralProphetModel(npr_features,npr_features,cm_var[0],lagged_features,\n",
    "#                                          train_basins,pickup_date,npr_cm_model_path)\n",
    "#     npr_cm_train = npr_cm_trainer.train(npr_train_df)\n",
    "#     npr_cm_data_dict = npr_cm_trainer.infer(npr_cmf_infer_df,npr_cm_train)\n",
    "#     npr_cm_data_dict = npr_cm_data_dict.reset_index()[[\"quarter\",\"SL BASIN (CODE)\",\"cm\"]]\n",
    "#     npr_rev_data_dict = npr_rev_data_dict[[\"quarter\",\"SL BASIN (CODE)\",\"rev\"]]\n",
    "#     npr_cm_data_dict = npr_cm_data_dict.merge(npr_rev_data_dict[[\"quarter\",\"SL BASIN (CODE)\",\"rev\"]].drop_duplicates(),\n",
    "#                             on=[\"quarter\",\"SL BASIN (CODE)\"],\n",
    "#                            how=\"inner\")\n",
    "    \n",
    "    \n",
    "    def convert_dict_to_df(data_dict):\n",
    "        baseline_data_dict = pd.DataFrame()\n",
    "        for basin in data_dict.keys():\n",
    "            df = data_dict[basin]\n",
    "            df = df.reset_index()\n",
    "            df[\"SL BASIN (CODE)\"] = basin\n",
    "            baseline_data_dict = baseline_data_dict.append(df)\n",
    "        return baseline_data_dict\n",
    "\n",
    "    ### RF Model\n",
    "    cm_model_path = os.path.join(MODEL_PATH, \"cm\",\"RF\")\n",
    "    cm_trainer = RfModel(cm_features,cm_var,train_basins,pickup_date,cm_model_path)\n",
    "    cm_trainer.train(train_df)\n",
    "    cm_data_dict = cm_trainer.infer(cmf_infer_df)\n",
    "    baseline_data_dict = convert_dict_to_df(cm_data_dict)\n",
    "\n",
    "#     pr_cm_model_path = os.path.join(MODEL_PATH, \"cm\",\"Prophet\")\n",
    "#     pr_cm_trainer = ProphetModel(pr_cm_features,pr_cm_features,cm_var,train_basins,pickup_date,pr_cm_model_path)\n",
    "#     pr_cm_trainer.train(pr_train_df)\n",
    "#     pr_cmf_infer_df = pr_cmf_infer_df.reset_index().rename({'quarter':'ds'},axis='columns')\n",
    "#     pr_cm_data_dict = pr_cm_trainer.infer(pr_cmf_infer_df)\n",
    "#     pr_cm_data_dict = pr_cm_data_dict.rename({'ds':'quarter'},axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "    # Ground truth\n",
    "    ground_truth = train_df[[\"SL BASIN (CODE)\",\"cm\",\"rev\"]].reset_index().drop_duplicates().dropna()\n",
    "    ground_truth = ground_truth.sort_values([\"SL BASIN (CODE)\",\"quarter\"])\n",
    "    ground_truth = ground_truth.rename(mapper={\"cm\":\"actual_contribution_margin\",\"rev\":\"actual_revenue\"},axis=1)\n",
    "    ground_truth = ground_truth.reset_index().drop([\"index\"],axis=1)\n",
    "    ground_truth.to_csv('ground_truth.csv')\n",
    "    # past dataframes\n",
    "    try:\n",
    "        max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "        lr_query = \"\"\"\n",
    "        SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date >= '{}' \n",
    "        \"\"\".format(str(max_date)[-6:])\n",
    "        multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "        multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "        multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\"]]\n",
    "\n",
    "    except:\n",
    "        multi_model_df = pd.DataFrame()\n",
    "    refresh_date = refresh_date.replace(' ', '') \n",
    "    pp = postprocess(refresh_date, cxn_ODS)\n",
    "    pp.post_process( train_df, baseline_data_dict,\"RF\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, pr_cm_data_dict,\"Prophet\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, npr_cm_data_dict,\"Neural Prophet\", multi_model_df,ground_truth)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "    #         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "        lr_query = \"\"\"\n",
    "        SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date >= '{}' \n",
    "        \"\"\".format(str(max_date)[-6:])\n",
    "        multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "        multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "    #     multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\",\"refresh_date\"]]\n",
    "\n",
    "    except:\n",
    "        multi_model_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    model_sel = model_selection(refresh_date,train_basins)\n",
    "    try:\n",
    "        best_df = model_sel.best_model(multi_model_df)\n",
    "\n",
    "        best_df.to_sql(con=cxn_ODS, name='cmf3_1_mvp3_Q2_best',if_exists = 'append',index=None)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "#     counter = 0\n",
    "#     main(counter)\n",
    "    for counter in range(4,):\n",
    "        dff = pd.DataFrame(columns = ['level', 'date', 'quarter', 'actual_revenue', 'predicted_revenue',\n",
    "       'revenue_error%', 'actual_cm', 'predicted_cm', 'cm_error%',\n",
    "       'refresh_date'])\n",
    "        main(counter,dff)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a117a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b71e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919286e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "lr_query = \"\"\"\n",
    "SELECT * FROM cmf3_1_mvp3_Q2  \n",
    "\"\"\"\n",
    "multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "multi_model_df.to_csv('multi_model_df3.csv')\n",
    "#     multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2_best\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "lr_query = \"\"\"\n",
    "SELECT * FROM cmf3_1_mvp3_Q2_best  \n",
    "\"\"\"\n",
    "multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "multi_model_df.to_csv('cmf3_1_mvp3_Q2_best.csv')\n",
    "#     multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70887d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q1_best\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "lr_query = \"\"\"\n",
    "SELECT * FROM cmf3_1_mvp3_Q1_best  \n",
    "\"\"\"\n",
    "multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "multi_model_df.to_csv('cmf3_1_mvp3_Q1_best.csv')\n",
    "#     multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bee9ba",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8583d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter=4\n",
    "print(\"---------  Counter: \", counter)\n",
    "path = 'C:/Users/bgondaliya/git/cmf-mvp3-quarter/bin/local/'\n",
    "\n",
    "# 0. get pond Credentials\n",
    "cred = credentials(path)\n",
    "cxn_ODS,cxn_6438 = cred.read_cred()\n",
    "\n",
    "# 1. to get the data\n",
    "data = TeleportData(cxn_6438,cxn_ODS)\n",
    "raw_df = data.get_data()\n",
    "oil_df = data.get_eia_data(cxn_ODS)\n",
    "#     raw_df.to_csv('raw_df.csv')\n",
    "#     oil_df.to_csv('oil_df.csv')\n",
    "\n",
    "# 2.define variables\n",
    "basins = ['AML', 'ASIA', 'MENA', 'OAT', 'RCA', 'Worldwide']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_start_date = \"2017-01-01\"\n",
    "pickup_date = pd.to_datetime(\"2022-02-01\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3)#str(datetime.date(date.today().year, date.today().month, 1))\n",
    "quarter = (pickup_date.month - 1) // 3 + 1\n",
    "forecast_start_date = pickup_date.strftime('%YQ{}'.format(quarter))\n",
    "refresh_date =  pd.to_datetime(\"2022-02-16\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3) #str(date.today())\n",
    "refresh_date = refresh_date.strftime('%YQ{}'.format(quarter))\n",
    "duration_of_forecast = 4 #quarter\n",
    "\n",
    "\n",
    "print(\"refresh_date:\",refresh_date)\n",
    "#     data_start_date = \"2020-05-01\"\n",
    "#     forecast_start_date = str(pd.to_datetime(\"2022-03-01\",format=\"%Y-%m-%d\")+ relativedelta(months=counter))#str(datetime.date(date.today().year, date.today().month, 1))\n",
    "#     refresh_date =  str(pd.to_datetime(\"2022-03-26\",format=\"%Y-%m-%d\")+ relativedelta(months=counter)) #str(date.today())\n",
    "#     duration_of_forecast = 12\n",
    "\n",
    "\n",
    "raw_df = raw_df[raw_df[\"SL BASIN (CODE)\"]!=\"SL_Elims\"]\n",
    "raw_df[\"SL BASIN (CODE)\"] = raw_df[\"SL BASIN (CODE)\"]+\"-\"+raw_df[\"SL DIVISION (CODE)\"]\n",
    "\n",
    "\n",
    "# Dep Vars\n",
    "rev_var = [\"rev\"]\n",
    "cm_var = ['cm']\n",
    "\n",
    "# Baseline Model\n",
    "\n",
    "rev_features = ['c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', 'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)',\n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)']\n",
    "\n",
    "\n",
    "\n",
    "cm_features = [\n",
    "        'rev', 'c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', 'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)',\n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "       'rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)']\n",
    "\n",
    "# Prophet Model\n",
    "pr_rev_features = ['c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD',\n",
    "        'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)',\n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "                ]\n",
    "\n",
    "pr_cm_features = ['c4c_rev', 'gac_rev','rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', \n",
    "        'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)', \n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "       'rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)',]\n",
    "\n",
    "\n",
    "# Neural Prophet Model\n",
    "\n",
    "npr_features = ['c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', \n",
    "        'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)', \n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',]\n",
    "\n",
    "\n",
    "lagged_features = ['rev','rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)']\n",
    "\n",
    "\n",
    "basins = ['AML-DAI',\n",
    " 'AML-MSP',\n",
    " 'AML-N/A',\n",
    " 'AML-NEO',\n",
    " 'AML-OTH',\n",
    " 'AML-PRS',\n",
    " 'AML-RPF',\n",
    " 'AML-WEC',\n",
    " 'ASIA-DAI',\n",
    " 'ASIA-MSP',\n",
    " 'ASIA-N/A',\n",
    " 'ASIA-NEO',\n",
    " 'ASIA-OTH',\n",
    " 'ASIA-PRS',\n",
    " 'ASIA-RPF',\n",
    " 'ASIA-WEC',\n",
    " 'GHQ-DAI',\n",
    " 'GHQ-MSP',\n",
    " 'GHQ-NEO',\n",
    " 'GHQ-OTH',\n",
    " 'GHQ-PRS',\n",
    " 'GHQ-RPF',\n",
    " 'GHQ-WEC',\n",
    " 'MENA-DAI',\n",
    " 'MENA-MSP',\n",
    " 'MENA-N/A',\n",
    " 'MENA-NEO',\n",
    " 'MENA-OTH',\n",
    " 'MENA-PRS',\n",
    " 'MENA-RPF',\n",
    " 'MENA-WEC',\n",
    " 'N/A-DAI',\n",
    " 'OAT-DAI',\n",
    " 'OAT-MSP',\n",
    " 'OAT-N/A',\n",
    " 'OAT-NEO',\n",
    " 'OAT-OTH',\n",
    " 'OAT-PRS',\n",
    " 'OAT-RPF',\n",
    " 'OAT-WEC',\n",
    " 'RCA-DAI',\n",
    " 'RCA-MSP',\n",
    " 'RCA-OTH',\n",
    " 'RCA-PRS',\n",
    " 'RCA-RPF',\n",
    " 'RCA-WEC',\n",
    " 'Worldwide-DAI',\n",
    " 'Worldwide-MSP',\n",
    " 'Worldwide-N/A',\n",
    " 'Worldwide-NEO',\n",
    " 'Worldwide-OTH',\n",
    " 'Worldwide-PRS',\n",
    " 'Worldwide-RPF',\n",
    " 'Worldwide-WEC'\n",
    "    ]\n",
    "\n",
    "\n",
    "# 3. transform the data for Rev\n",
    "## RF\n",
    "tt = TrainingTransformer(data_start_date,duration_of_forecast,basins)\n",
    "\n",
    "\n",
    "tt.fit(raw_df)\n",
    "\n",
    "train_df = tt.transform(raw_df,oil_df)\n",
    "\n",
    "train_df = train_df[train_df.index<forecast_start_date]\n",
    "pr_train_df = train_df.copy()\n",
    "pr_train_df = pr_train_df.reset_index()\n",
    "\n",
    "it = InferenceRevTransformer(duration_of_forecast,pickup_date,basins)\n",
    "it.fit(raw_df)\n",
    "infer_df = it.transform(raw_df,oil_df)\n",
    "infer_df.to_csv(\"infer_df.csv\")\n",
    "pr_infer_df = infer_df.copy()\n",
    "pr_infer_df = pr_infer_df.reset_index()\n",
    "\n",
    "npr_train_df = pr_train_df.copy()\n",
    "npr_infer_df = pr_infer_df.copy()\n",
    "npr_infer_df.to_csv(\"npr_infer_df.csv\")\n",
    "\n",
    "train_basins = set([\n",
    "     'MENA-WEC',\n",
    "     'ASIA-DAI',\n",
    "#          'OAT-RPF',\n",
    "#          'AML-WEC',\n",
    "#          'AML-DAI',\n",
    "#          'RCA-WEC',\n",
    "#          'OAT-WEC',\n",
    "#          'ASIA-RPF',\n",
    "#          'ASIA-PRS',\n",
    "#          'ASIA-WEC',\n",
    "#          'RCA-RPF',\n",
    "#          'RCA-DAI',\n",
    "#          'AML-PRS',\n",
    "#          'AML-RPF',\n",
    "#          'OAT-PRS',\n",
    "#          'MENA-PRS',\n",
    "#          'OAT-DAI',\n",
    "#          'MENA-RPF',\n",
    "#          'RCA-PRS',\n",
    "#          'MENA-DAI',\n",
    "#         'Worldwide-DAI','Worldwide-WEC','Worldwide-PRS','Worldwide-RPF'\n",
    "])\n",
    "\n",
    "# Part-3\n",
    "### RF Model\n",
    "rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"RF\")\n",
    "print('path----',rev_model_path)\n",
    "rev_trainer = RfModel(rev_features,rev_var,train_basins,pickup_date,rev_model_path)\n",
    "rev_trainer.train(train_df)\n",
    "rev_data_dict = rev_trainer.infer(infer_df)\n",
    "\n",
    "\n",
    "#     pr_rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"Prophet\")\n",
    "#     pr_rev_trainer = ProphetModel(pr_rev_features,pr_rev_features,rev_var,train_basins,pickup_date,pr_rev_model_path)\n",
    "#     pr_rev_trainer.train(pr_train_df)\n",
    "#     pr_rev_data_dict = pr_rev_trainer.infer(pr_infer_df)\n",
    "\n",
    "\n",
    "#     npr_rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"NeuralPr\")\n",
    "#     npr_rev_trainer = NeuralProphetModel(npr_features,npr_features,rev_var[0],[],\n",
    "#                                          train_basins,pickup_date,rev_model_path)\n",
    "#     npr_train = npr_rev_trainer.train(npr_train_df)\n",
    "#     npr_rev_data_dict = npr_rev_trainer.infer(npr_infer_df, npr_train)\n",
    "\n",
    "\n",
    "## 4. \n",
    "pickup_date2 = pd.to_datetime(pickup_date)+ relativedelta(months=-12)\n",
    "\n",
    "it = InferenceRevTransformer(duration_of_forecast+4,pickup_date2,basins)\n",
    "it.fit(raw_df)\n",
    "infer_df = it.transform(raw_df,oil_df)\n",
    "\n",
    "# 5. Preprocess CM data\n",
    "ict = InferenceConMarTrTransformer(rev_data_dict, forecast_start_date)\n",
    "ict.fit(infer_df)\n",
    "cmf_infer_df = ict.transform(infer_df)    \n",
    "cmf_infer_df.to_csv('cmf_infer_df.csv')\n",
    "\n",
    "\n",
    "# 5.1 \n",
    "\n",
    "#     icp = InferenceConMarPrTransformer(pr_rev_data_dict,train_basins, forecast_start_date)\n",
    "#     icp.fit(pr_infer_df)\n",
    "#     pr_cmf_infer_df = icp.transform(infer_df)\n",
    "\n",
    "#     icnp = InferenceConMarPrTransformer(npr_rev_data_dict,train_basins,forecast_start_date)\n",
    "#     icnp.fit(npr_infer_df)\n",
    "#     npr_cmf_infer_df = icnp.transform(infer_df)\n",
    "# 5.2\n",
    "#     npr_cm_model_path = os.path.join(MODEL_PATH, \"cm\", \"NeuralPr\")\n",
    "#     npr_cm_trainer = NeuralProphetModel(npr_features,npr_features,cm_var[0],lagged_features,\n",
    "#                                          train_basins,pickup_date,npr_cm_model_path)\n",
    "#     npr_cm_train = npr_cm_trainer.train(npr_train_df)\n",
    "#     npr_cm_data_dict = npr_cm_trainer.infer(npr_cmf_infer_df,npr_cm_train)\n",
    "#     npr_cm_data_dict = npr_cm_data_dict.reset_index()[[\"quarter\",\"SL BASIN (CODE)\",\"cm\"]]\n",
    "#     npr_rev_data_dict = npr_rev_data_dict[[\"quarter\",\"SL BASIN (CODE)\",\"rev\"]]\n",
    "#     npr_cm_data_dict = npr_cm_data_dict.merge(npr_rev_data_dict[[\"quarter\",\"SL BASIN (CODE)\",\"rev\"]].drop_duplicates(),\n",
    "#                             on=[\"quarter\",\"SL BASIN (CODE)\"],\n",
    "#                            how=\"inner\")\n",
    "\n",
    "\n",
    "def convert_dict_to_df(data_dict):\n",
    "    baseline_data_dict = pd.DataFrame()\n",
    "    for basin in data_dict.keys():\n",
    "        df = data_dict[basin]\n",
    "        df = df.reset_index()\n",
    "        df[\"SL BASIN (CODE)\"] = basin\n",
    "        baseline_data_dict = baseline_data_dict.append(df)\n",
    "    return baseline_data_dict\n",
    "\n",
    "### RF Model\n",
    "cm_model_path = os.path.join(MODEL_PATH, \"cm\",\"RF\")\n",
    "cm_trainer = RfModel(cm_features,cm_var,train_basins,pickup_date,cm_model_path)\n",
    "cm_trainer.train(train_df)\n",
    "cm_data_dict = cm_trainer.infer(cmf_infer_df)\n",
    "baseline_data_dict = convert_dict_to_df(cm_data_dict)\n",
    "\n",
    "#     pr_cm_model_path = os.path.join(MODEL_PATH, \"cm\",\"Prophet\")\n",
    "#     pr_cm_trainer = ProphetModel(pr_cm_features,pr_cm_features,cm_var,train_basins,pickup_date,pr_cm_model_path)\n",
    "#     pr_cm_trainer.train(pr_train_df)\n",
    "#     pr_cmf_infer_df = pr_cmf_infer_df.reset_index().rename({'quarter':'ds'},axis='columns')\n",
    "#     pr_cm_data_dict = pr_cm_trainer.infer(pr_cmf_infer_df)\n",
    "#     pr_cm_data_dict = pr_cm_data_dict.rename({'ds':'quarter'},axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "# Ground truth\n",
    "ground_truth = train_df[[\"SL BASIN (CODE)\",\"cm\",\"rev\"]].reset_index().drop_duplicates().dropna()\n",
    "ground_truth = ground_truth.sort_values([\"SL BASIN (CODE)\",\"quarter\"])\n",
    "ground_truth = ground_truth.rename(mapper={\"cm\":\"actual_contribution_margin\",\"rev\":\"actual_revenue\"},axis=1)\n",
    "ground_truth = ground_truth.reset_index().drop([\"index\"],axis=1)\n",
    "ground_truth.to_csv('ground_truth.csv')\n",
    "# past dataframes\n",
    "try:\n",
    "    max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "    lr_query = \"\"\"\n",
    "    SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date >= '{}' \n",
    "    \"\"\".format(str(max_date)[-6:])\n",
    "    multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "    multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "    multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\"]]\n",
    "\n",
    "except:\n",
    "    multi_model_df = pd.DataFrame()\n",
    "refresh_date = refresh_date.replace(' ', '') \n",
    "pp = postprocess(refresh_date, cxn_ODS)\n",
    "pp.post_process( train_df, baseline_data_dict,\"RF\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, pr_cm_data_dict,\"Prophet\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, npr_cm_data_dict,\"Neural Prophet\", multi_model_df,ground_truth)\n",
    "\n",
    "\n",
    "try:\n",
    "    max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "    lr_query = \"\"\"\n",
    "    SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date >= '{}' \n",
    "    \"\"\".format(str(max_date)[-6:])\n",
    "    multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "    multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "#     multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\",\"refresh_date\"]]\n",
    "\n",
    "except:\n",
    "    multi_model_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15943b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel = model_selection(refresh_date,train_basins)\n",
    "model_sel.best_model(multi_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_sel = model_selection(refresh_date,train_basins)\n",
    "try:\n",
    "    best_df = model_sel.best_model(multi_model_df)\n",
    "\n",
    "    best_df.to_sql(con=cxn_ODS, name='cmf3_1_mvp3_Q2_best',if_exists = 'append',index=None)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192dcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  6 11:17:50 2023\n",
    "\n",
    "@author: BGondaliya\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "class model_selection:\n",
    "    def __init__(self,refresh_date,train_basins):\n",
    "        self.ref_date = refresh_date\n",
    "        self.refresh_date = str(pd.to_datetime(refresh_date).replace(day=1)) #str(date.today(\n",
    "        temp = pd.to_datetime(refresh_date) + relativedelta(months=-12)\n",
    "        self.cutoff_date = temp.strftime('%YQ{}'.format( (temp.month - 1) // 3 + 1))\n",
    "        self.train_basins = train_basins\n",
    "\n",
    "\n",
    "    def best_model(self, X):\n",
    "        data = X[X['refresh_date']== self.ref_date]\n",
    "        data = data[(data['quarter'] > self.cutoff_date) & (data['quarter'] < self.ref_date)]\n",
    "\n",
    "        data['abs_rev_error'] = abs(data['revenue_error'])\n",
    "        data['abs_cm_error'] = abs(data['contribution_margin_error'])\n",
    "        \n",
    "        grouped_df = data.groupby(['SL BASIN (CODE)', 'model','refresh_date']).agg({'abs_rev_error': 'mean', 'abs_cm_error': 'mean'})\n",
    "        grouped_df = grouped_df.dropna()\n",
    "        \n",
    "        grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "        min_indices = grouped['abs_rev_error'].idxmin()\n",
    "        best_rev_df = grouped_df.loc[min_indices]\n",
    "        \n",
    "        grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "\n",
    "        min_indices = grouped['abs_cm_error'].idxmin()\n",
    "        best_cm_df = grouped_df.loc[min_indices]\n",
    "        \n",
    "        # to extract dataframe for best model\n",
    "        data = X[X['refresh_date']== self.ref_date]\n",
    "#         data = data[data['refresh_date']==self.refresh_date]\n",
    "        ans = pd.DataFrame(columns=['quarter', 'SL BASIN (CODE)', 'rev', 'actual_revenue',\n",
    "               'revenue_error', 'YM', 'refresh_date', 'level', 'rev_Model', 'cm',\n",
    "               'actual_contribution_margin', 'contribution_margin_error', 'cm_Model'])   \n",
    "        for basin in self.train_basins:\n",
    "            print(basin)\n",
    "\n",
    "            rev_model = best_rev_df.loc[best_rev_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "            cm_model = best_cm_df.loc[best_cm_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "\n",
    "            df_rev = data[(data['SL BASIN (CODE)']==basin) &(data['model']==\"RF\")][['quarter', 'SL BASIN (CODE)', 'rev',\n",
    "                    'actual_revenue','revenue_error', 'YM', 'refresh_date',\n",
    "                   'level']]\n",
    "            df_rev['rev_Model'] = str(rev_model[0])\n",
    "            df_rev = df_rev.drop_duplicates()\n",
    "\n",
    "            df_cm = data[(data['SL BASIN (CODE)']==basin) &(data['model']==\"RF\")][['quarter', 'SL BASIN (CODE)', 'cm',\n",
    "                   'actual_contribution_margin', \n",
    "                   'contribution_margin_error', ]]\n",
    "            df_cm['cm_Model'] = str(cm_model[0])\n",
    "            df_cm = df_cm.drop_duplicates()\n",
    "\n",
    "            ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
    "\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_sel = model_selection(refresh_date,train_basins)\n",
    "try:\n",
    "    best_df = model_sel.best_model(multi_model_df)\n",
    "\n",
    "    best_df.to_sql(con=cxn_ODS, name='cmf3_1_mvp3_Q2_best',if_exists = 'append',index=None)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dba298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start_date = \"2017-01-01\"\n",
    "pickup_date = pd.to_datetime(\"2022-02-01\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3)#str(datetime.date(date.today().year, date.today().month, 1))\n",
    "quarter = (pickup_date.month - 1) // 3 + 1\n",
    "forecast_start_date = pickup_date.strftime('%YQ{}'.format(quarter))\n",
    "refresh_date =  pd.to_datetime(\"2022-02-16\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3) #str(date.today())\n",
    "refresh_date = refresh_date.strftime('%YQ{}'.format(quarter))\n",
    "duration_of_forecast = 4 #quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0066eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "lr_query = \"\"\"\n",
    "SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date >= '{}' \n",
    "\"\"\".format(str(max_date)[-6:])\n",
    "multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "#     multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\",\"refresh_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f46350",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179404be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel = model_selection(refresh_date,train_basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf73fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526e3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85099eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date = refresh_date\n",
    "refresh_date = str(pd.to_datetime(refresh_date).replace(day=1)) \n",
    "cutoff_date = pd.to_datetime(refresh_date) + relativedelta(months=-12)\n",
    "cutoff_date = cutoff_date.strftime('%YQ{}'.format( (cutoff_date.month - 1) // 3 + 1))\n",
    "train_basins = train_basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da297712",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = multi_model_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e232ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['refresh_date']== ref_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X[X['refresh_date']== ref_date]\n",
    "data = data[(data['quarter'] > cutoff_date) & (data['quarter'] < ref_date)]\n",
    "\n",
    "data['abs_rev_error'] = abs(data['revenue_error'])\n",
    "data['abs_cm_error'] = abs(data['contribution_margin_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = data.groupby(['SL BASIN (CODE)', 'model','refresh_date']).agg({'abs_rev_error': 'mean', 'abs_cm_error': 'mean'})\n",
    "grouped_df = grouped_df.dropna()\n",
    "grouped_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "min_indices = grouped['abs_rev_error'].idxmin()\n",
    "min_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_rev_df = grouped_df.loc[min_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "\n",
    "min_indices = grouped['abs_cm_error'].idxmin()\n",
    "best_cm_df = grouped_df.loc[min_indices]\n",
    "\n",
    "# to extract dataframe for best model\n",
    "data = X[X['refresh_date']== ref_date]\n",
    "#         data = data[data['refresh_date']==self.refresh_date]\n",
    "ans = pd.DataFrame(columns=['YEARMONTH', 'SL BASIN (CODE)', 'rev', 'actual_revenue',\n",
    "       'revenue_error', 'YM', 'refresh_date', 'level', 'rev_Model', 'cm',\n",
    "       'actual_contribution_margin', 'contribution_margin_error', 'cm_Model'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13682fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin ='ASIA-DAI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_model = best_rev_df.loc[best_rev_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39160942",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_model = best_cm_df.loc[best_cm_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5356ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data['model']==best_cm_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_cm_df = best_cm_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f07f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = data[(data['SL BASIN (CODE)']==basin) & (data['model']==rev_model[0])][['quarter', 'SL BASIN (CODE)', 'rev',\n",
    "                    'actual_revenue','revenue_error', 'YM', 'refresh_date',\n",
    "                   'level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294df03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a230d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cm_df[(best_cm_df['SL BASIN (CODE)']==basin) &(best_cm_df['model']==\"RF\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aade19",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cm_df[(best_cm_df['SL BASIN (CODE)']==basin) &(best_cm_df['model']==\"RF\")][['SL BASIN (CODE)',\n",
    "                'abs_rev_error','abs_cm_error',  'refresh_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ad3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36772df",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cm_df.loc[best_cm_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebeab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rev_df[(best_rev_df.index.get_level_values('SL BASIN (CODE)')==basin) &(best_rev_df.index.get_level_values('model')==rev_model[0])][[\n",
    "                'abs_rev_error','abs_cm_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538ba16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10439adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin in train_basins:\n",
    "        print(basin)\n",
    "\n",
    "        rev_model = best_rev_df.loc[best_rev_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "        cm_model = best_cm_df.loc[best_cm_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "        \n",
    "#         best_cm_df = best_cm_df.reset_index()\n",
    "#         best_rev_df = best_rev_df.reset_index()\n",
    "        \n",
    "        df_rev = best_rev_df[(best_rev_df.index.get_level_values('SL BASIN (CODE)')==basin) &(best_rev_df.index.get_level_values('model')==rev_model[0])][[\n",
    "                'abs_rev_error','abs_cm_error']]\n",
    "\n",
    "        df_rev['rev_Model'] = str(rev_model[0])\n",
    "        df_rev = df_rev.drop_duplicates()\n",
    "\n",
    "        df_cm = best_cm_df[(best_cm_df.index.get_level_values('SL BASIN (CODE)')==basin) &(best_cm_df.index.get_level_values('model')==cm_model[0])][[\n",
    "                'abs_rev_error','abs_cm_error']]\n",
    "        df_cm['cm_Model'] = str(cm_model[0])\n",
    "        df_cm = df_cm.drop_duplicates()\n",
    "        break\n",
    "#         ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52724d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_rev.reset_index(),df_cm.reset_index()[, how='left', on = ['SL BASIN (CODE)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.DataFrame(columns=[ 'SL BASIN (CODE)', 'rev', 'actual_revenue',\n",
    "               'revenue_error', 'YM', 'refresh_date', 'level', 'rev_Model', 'cm',\n",
    "               'actual_contribution_margin', 'contribution_margin_error', 'cm_Model'])   \n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337befe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  6 11:17:50 2023\n",
    "\n",
    "@author: BGondaliya\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "class model_selection:\n",
    "    def __init__(self,refresh_date,train_basins):\n",
    "        self.ref_date = refresh_date\n",
    "        self.refresh_date = str(pd.to_datetime(refresh_date).replace(day=1)) #str(date.today(\n",
    "        temp = pd.to_datetime(refresh_date) + relativedelta(months=-12)\n",
    "        self.cutoff_date = temp.strftime('%YQ{}'.format( (temp.month - 1) // 3 + 1))\n",
    "        self.train_basins = train_basins\n",
    "\n",
    "\n",
    "    def best_model(self, X):\n",
    "        data = X[X['refresh_date']== self.ref_date]\n",
    "        data = data[(data['quarter'] > self.cutoff_date) & (data['quarter'] < self.ref_date)]\n",
    "\n",
    "        data['abs_rev_error'] = abs(data['revenue_error'])\n",
    "        data['abs_cm_error'] = abs(data['contribution_margin_error'])\n",
    "        \n",
    "        grouped_df = data.groupby(['SL BASIN (CODE)', 'model','refresh_date']).agg({'abs_rev_error': 'mean', 'abs_cm_error': 'mean'})\n",
    "        grouped_df = grouped_df.dropna()\n",
    "        \n",
    "        grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "        min_indices = grouped['abs_rev_error'].idxmin()\n",
    "        best_rev_df = grouped_df.loc[min_indices]\n",
    "        \n",
    "        grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "\n",
    "        min_indices = grouped['abs_cm_error'].idxmin()\n",
    "        best_cm_df = grouped_df.loc[min_indices]\n",
    "        \n",
    "        # to extract dataframe for best model\n",
    "        data = X[X['refresh_date']== self.ref_date]\n",
    "#         data = data[data['refresh_date']==self.refresh_date]\n",
    "        ans = pd.DataFrame(columns=['quarter', 'SL BASIN (CODE)', 'rev', 'actual_revenue',\n",
    "               'revenue_error', 'YM', 'refresh_date', 'level', 'rev_Model', 'cm',\n",
    "               'actual_contribution_margin', 'contribution_margin_error', 'cm_Model'])   \n",
    "        for basin in self.train_basins:\n",
    "            print(basin)\n",
    "\n",
    "            rev_model = best_rev_df.loc[best_rev_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "            cm_model = best_cm_df.loc[best_cm_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "\n",
    "            df_rev = data[(data['SL BASIN (CODE)']==basin) &(data['model']==rev_model[0])][['quarter', 'SL BASIN (CODE)', 'rev',\n",
    "                    'actual_revenue','revenue_error', 'YM', 'refresh_date',\n",
    "                   'level']]\n",
    "            df_rev['rev_Model'] = str(rev_model[0])\n",
    "            df_rev = df_rev.drop_duplicates()\n",
    "\n",
    "            df_cm = data[(data['SL BASIN (CODE)']==basin) &(data['model']==cm_model[0])][['quarter', 'SL BASIN (CODE)', 'cm',\n",
    "                   'actual_contribution_margin', \n",
    "                   'contribution_margin_error', ]]\n",
    "            df_cm['cm_Model'] = str(cm_model[0])\n",
    "            df_cm = df_cm.drop_duplicates()\n",
    "\n",
    "            ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['quarter','SL BASIN (CODE)']))\n",
    "\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6de79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.best_model(multi_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    best_df = model_sel.best_model(multi_model_df)\n",
    "\n",
    "    best_df.to_sql(con=cxn_ODS, name='cmf3_1_mvp3_Q2_best',if_exists = 'append',index=None)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35127a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df.to_csv('best_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232671bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df.to_csv('multi_model_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b12f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------  Counter: \", counter)\n",
    "path = 'C:/Users/bgondaliya/git/cmf-mvp3-quarter/bin/local/'\n",
    "\n",
    "# 0. get pond Credentials\n",
    "cred = credentials(path)\n",
    "cxn_ODS,cxn_6438 = cred.read_cred()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98166765",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "lr_query = \"\"\"\n",
    "SELECT * FROM cmf3_1_mvp3_Q2 \n",
    "\"\"\"\n",
    "multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df.to_csv('multi_model_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073d6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4877fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.best_model(multi_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0873a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel = model_selection(refresh_date,train_basins)\n",
    "try:\n",
    "    best_df = model_sel.best_model(multi_model_df)\n",
    "\n",
    "    best_df.to_sql(con=cxn_ODS, name='cmf3_1_mvp3_Q2_best',if_exists = 'append',index=None)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa29358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebe3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29074334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter=5\n",
    "print(\"---------  Counter: \", counter)\n",
    "path = 'C:/Users/bgondaliya/git/cmf-mvp3-quarter/bin/local/'\n",
    "\n",
    "# 0. get pond Credentials\n",
    "cred = credentials(path)\n",
    "cxn_ODS,cxn_6438 = cred.read_cred()\n",
    "\n",
    "# 1. to get the data\n",
    "data = TeleportData(cxn_6438,cxn_ODS)\n",
    "raw_df = data.get_data()\n",
    "oil_df = data.get_eia_data(cxn_ODS)\n",
    "#     raw_df.to_csv('raw_df.csv')\n",
    "#     oil_df.to_csv('oil_df.csv')\n",
    "\n",
    "# 2.define variables\n",
    "basins = ['AML', 'ASIA', 'MENA', 'OAT', 'RCA', 'Worldwide']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_start_date = \"2017-01-01\"\n",
    "pickup_date = pd.to_datetime(\"2022-02-01\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3)#str(datetime.date(date.today().year, date.today().month, 1))\n",
    "quarter = (pickup_date.month - 1) // 3 + 1\n",
    "forecast_start_date = pickup_date.strftime('%YQ{}'.format(quarter))\n",
    "refresh_date =  pd.to_datetime(\"2022-02-16\",format=\"%Y-%m-%d\")+ relativedelta(months=counter*3) #str(date.today())\n",
    "refresh_date = refresh_date.strftime('%YQ{}'.format(quarter))\n",
    "duration_of_forecast = 4 #quarter\n",
    "\n",
    "\n",
    "print(\"refresh_date:\",refresh_date)\n",
    "#     data_start_date = \"2020-05-01\"\n",
    "#     forecast_start_date = str(pd.to_datetime(\"2022-03-01\",format=\"%Y-%m-%d\")+ relativedelta(months=counter))#str(datetime.date(date.today().year, date.today().month, 1))\n",
    "#     refresh_date =  str(pd.to_datetime(\"2022-03-26\",format=\"%Y-%m-%d\")+ relativedelta(months=counter)) #str(date.today())\n",
    "#     duration_of_forecast = 12\n",
    "\n",
    "\n",
    "raw_df = raw_df[raw_df[\"SL BASIN (CODE)\"]!=\"SL_Elims\"]\n",
    "raw_df[\"SL BASIN (CODE)\"] = raw_df[\"SL BASIN (CODE)\"]+\"-\"+raw_df[\"SL DIVISION (CODE)\"]\n",
    "\n",
    "\n",
    "# Dep Vars\n",
    "rev_var = [\"rev\"]\n",
    "cm_var = ['cm']\n",
    "\n",
    "# Baseline Model\n",
    "\n",
    "rev_features = ['c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', 'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)',\n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)']\n",
    "\n",
    "\n",
    "\n",
    "cm_features = [\n",
    "        'rev', 'c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', 'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)',\n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "       'rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)']\n",
    "\n",
    "# Prophet Model\n",
    "pr_rev_features = ['c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD',\n",
    "        'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)',\n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "                ]\n",
    "\n",
    "pr_cm_features = ['c4c_rev', 'gac_rev','rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', \n",
    "        'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)', \n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',\n",
    "       'rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)',]\n",
    "\n",
    "\n",
    "# Neural Prophet Model\n",
    "\n",
    "npr_features = ['c4c_rev', 'gac_rev',\n",
    "       'BC_OIL_PRICE_USD', 'WTI_OIL_PRICE_USD', \n",
    "        'gac_activity(t-1)',\n",
    "       'gac_activity(t-2)', 'gac_activity(t-3)', 'gac_activity(t+1)',\n",
    "       'gac_activity(t+2)', \n",
    "       'c4c_activity(t-1)', 'c4c_activity(t-2)', 'c4c_activity(t-3)',\n",
    "       'c4c_activity(t+1)', 'c4c_activity(t+2)', 'wti_activity(t-1)',\n",
    "       'wti_activity(t-2)', 'wti_activity(t-3)', 'wti_activity(t+1)',\n",
    "       'wti_activity(t+2)', 'btc_activity(t-1)', 'btc_activity(t-2)',\n",
    "       'btc_activity(t-3)', 'btc_activity(t+1)', 'btc_activity(t+2)',]\n",
    "\n",
    "\n",
    "lagged_features = ['rev','rev_activity(t-1)', 'rev_activity(t-2)', 'rev_activity(t-3)']\n",
    "\n",
    "\n",
    "basins = ['AML-DAI',\n",
    " 'AML-MSP',\n",
    " 'AML-N/A',\n",
    " 'AML-NEO',\n",
    " 'AML-OTH',\n",
    " 'AML-PRS',\n",
    " 'AML-RPF',\n",
    " 'AML-WEC',\n",
    " 'ASIA-DAI',\n",
    " 'ASIA-MSP',\n",
    " 'ASIA-N/A',\n",
    " 'ASIA-NEO',\n",
    " 'ASIA-OTH',\n",
    " 'ASIA-PRS',\n",
    " 'ASIA-RPF',\n",
    " 'ASIA-WEC',\n",
    " 'GHQ-DAI',\n",
    " 'GHQ-MSP',\n",
    " 'GHQ-NEO',\n",
    " 'GHQ-OTH',\n",
    " 'GHQ-PRS',\n",
    " 'GHQ-RPF',\n",
    " 'GHQ-WEC',\n",
    " 'MENA-DAI',\n",
    " 'MENA-MSP',\n",
    " 'MENA-N/A',\n",
    " 'MENA-NEO',\n",
    " 'MENA-OTH',\n",
    " 'MENA-PRS',\n",
    " 'MENA-RPF',\n",
    " 'MENA-WEC',\n",
    " 'N/A-DAI',\n",
    " 'OAT-DAI',\n",
    " 'OAT-MSP',\n",
    " 'OAT-N/A',\n",
    " 'OAT-NEO',\n",
    " 'OAT-OTH',\n",
    " 'OAT-PRS',\n",
    " 'OAT-RPF',\n",
    " 'OAT-WEC',\n",
    " 'RCA-DAI',\n",
    " 'RCA-MSP',\n",
    " 'RCA-OTH',\n",
    " 'RCA-PRS',\n",
    " 'RCA-RPF',\n",
    " 'RCA-WEC',\n",
    " 'Worldwide-DAI',\n",
    " 'Worldwide-MSP',\n",
    " 'Worldwide-N/A',\n",
    " 'Worldwide-NEO',\n",
    " 'Worldwide-OTH',\n",
    " 'Worldwide-PRS',\n",
    " 'Worldwide-RPF',\n",
    " 'Worldwide-WEC'\n",
    "    ]\n",
    "\n",
    "\n",
    "# 3. transform the data for Rev\n",
    "## RF\n",
    "tt = TrainingTransformer(data_start_date,duration_of_forecast,basins)\n",
    "\n",
    "\n",
    "tt.fit(raw_df)\n",
    "\n",
    "train_df = tt.transform(raw_df,oil_df)\n",
    "\n",
    "train_df = train_df[train_df.index<forecast_start_date]\n",
    "pr_train_df = train_df.copy()\n",
    "pr_train_df = pr_train_df.reset_index()\n",
    "\n",
    "it = InferenceRevTransformer(duration_of_forecast,pickup_date,basins)\n",
    "it.fit(raw_df)\n",
    "infer_df = it.transform(raw_df,oil_df)\n",
    "infer_df.to_csv(\"infer_df.csv\")\n",
    "pr_infer_df = infer_df.copy()\n",
    "pr_infer_df = pr_infer_df.reset_index()\n",
    "\n",
    "npr_train_df = pr_train_df.copy()\n",
    "npr_infer_df = pr_infer_df.copy()\n",
    "npr_infer_df.to_csv(\"npr_infer_df.csv\")\n",
    "\n",
    "train_basins = set([\n",
    "     'MENA-WEC',\n",
    "     'ASIA-DAI',\n",
    "     'OAT-RPF',\n",
    "     'AML-WEC',\n",
    "     'AML-DAI',\n",
    "     'RCA-WEC',\n",
    "     'OAT-WEC',\n",
    "     'ASIA-RPF',\n",
    "     'ASIA-PRS',\n",
    "     'ASIA-WEC',\n",
    "     'RCA-RPF',\n",
    "     'RCA-DAI',\n",
    "     'AML-PRS',\n",
    "     'AML-RPF',\n",
    "     'OAT-PRS',\n",
    "     'MENA-PRS',\n",
    "     'OAT-DAI',\n",
    "     'MENA-RPF',\n",
    "     'RCA-PRS',\n",
    "     'MENA-DAI',\n",
    "    'Worldwide-DAI','Worldwide-WEC','Worldwide-PRS','Worldwide-RPF'\n",
    "])\n",
    "\n",
    "# Part-3\n",
    "### RF Model\n",
    "rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"RF\")\n",
    "print('path----',rev_model_path)\n",
    "rev_trainer = RfModel(rev_features,rev_var,train_basins,pickup_date,rev_model_path)\n",
    "rev_trainer.train(train_df)\n",
    "rev_data_dict = rev_trainer.infer(infer_df)\n",
    "\n",
    "\n",
    "#     pr_rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"Prophet\")\n",
    "#     pr_rev_trainer = ProphetModel(pr_rev_features,pr_rev_features,rev_var,train_basins,pickup_date,pr_rev_model_path)\n",
    "#     pr_rev_trainer.train(pr_train_df)\n",
    "#     pr_rev_data_dict = pr_rev_trainer.infer(pr_infer_df)\n",
    "\n",
    "\n",
    "#     npr_rev_model_path = os.path.join(MODEL_PATH, \"rev\", \"NeuralPr\")\n",
    "#     npr_rev_trainer = NeuralProphetModel(npr_features,npr_features,rev_var[0],[],\n",
    "#                                          train_basins,pickup_date,rev_model_path)\n",
    "#     npr_train = npr_rev_trainer.train(npr_train_df)\n",
    "#     npr_rev_data_dict = npr_rev_trainer.infer(npr_infer_df, npr_train)\n",
    "\n",
    "\n",
    "## 4. \n",
    "pickup_date2 = pd.to_datetime(pickup_date)+ relativedelta(months=-12)\n",
    "\n",
    "it = InferenceRevTransformer(duration_of_forecast+4,pickup_date2,basins)\n",
    "it.fit(raw_df)\n",
    "infer_df = it.transform(raw_df,oil_df)\n",
    "\n",
    "# 5. Preprocess CM data\n",
    "ict = InferenceConMarTrTransformer(rev_data_dict, forecast_start_date)\n",
    "ict.fit(infer_df)\n",
    "cmf_infer_df = ict.transform(infer_df)    \n",
    "cmf_infer_df.to_csv('cmf_infer_df.csv')\n",
    "\n",
    "\n",
    "# 5.1 \n",
    "\n",
    "#     icp = InferenceConMarPrTransformer(pr_rev_data_dict,train_basins, forecast_start_date)\n",
    "#     icp.fit(pr_infer_df)\n",
    "#     pr_cmf_infer_df = icp.transform(infer_df)\n",
    "\n",
    "#     icnp = InferenceConMarPrTransformer(npr_rev_data_dict,train_basins,forecast_start_date)\n",
    "#     icnp.fit(npr_infer_df)\n",
    "#     npr_cmf_infer_df = icnp.transform(infer_df)\n",
    "# 5.2\n",
    "#     npr_cm_model_path = os.path.join(MODEL_PATH, \"cm\", \"NeuralPr\")\n",
    "#     npr_cm_trainer = NeuralProphetModel(npr_features,npr_features,cm_var[0],lagged_features,\n",
    "#                                          train_basins,pickup_date,npr_cm_model_path)\n",
    "#     npr_cm_train = npr_cm_trainer.train(npr_train_df)\n",
    "#     npr_cm_data_dict = npr_cm_trainer.infer(npr_cmf_infer_df,npr_cm_train)\n",
    "#     npr_cm_data_dict = npr_cm_data_dict.reset_index()[[\"quarter\",\"SL BASIN (CODE)\",\"cm\"]]\n",
    "#     npr_rev_data_dict = npr_rev_data_dict[[\"quarter\",\"SL BASIN (CODE)\",\"rev\"]]\n",
    "#     npr_cm_data_dict = npr_cm_data_dict.merge(npr_rev_data_dict[[\"quarter\",\"SL BASIN (CODE)\",\"rev\"]].drop_duplicates(),\n",
    "#                             on=[\"quarter\",\"SL BASIN (CODE)\"],\n",
    "#                            how=\"inner\")\n",
    "\n",
    "\n",
    "def convert_dict_to_df(data_dict):\n",
    "    baseline_data_dict = pd.DataFrame()\n",
    "    for basin in data_dict.keys():\n",
    "        df = data_dict[basin]\n",
    "        df = df.reset_index()\n",
    "        df[\"SL BASIN (CODE)\"] = basin\n",
    "        baseline_data_dict = baseline_data_dict.append(df)\n",
    "    return baseline_data_dict\n",
    "\n",
    "### RF Model\n",
    "cm_model_path = os.path.join(MODEL_PATH, \"cm\",\"RF\")\n",
    "cm_trainer = RfModel(cm_features,cm_var,train_basins,pickup_date,cm_model_path)\n",
    "cm_trainer.train(train_df)\n",
    "cm_data_dict = cm_trainer.infer(cmf_infer_df)\n",
    "baseline_data_dict = convert_dict_to_df(cm_data_dict)\n",
    "\n",
    "#     pr_cm_model_path = os.path.join(MODEL_PATH, \"cm\",\"Prophet\")\n",
    "#     pr_cm_trainer = ProphetModel(pr_cm_features,pr_cm_features,cm_var,train_basins,pickup_date,pr_cm_model_path)\n",
    "#     pr_cm_trainer.train(pr_train_df)\n",
    "#     pr_cmf_infer_df = pr_cmf_infer_df.reset_index().rename({'quarter':'ds'},axis='columns')\n",
    "#     pr_cm_data_dict = pr_cm_trainer.infer(pr_cmf_infer_df)\n",
    "#     pr_cm_data_dict = pr_cm_data_dict.rename({'ds':'quarter'},axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "# Ground truth\n",
    "ground_truth = train_df[[\"SL BASIN (CODE)\",\"cm\",\"rev\"]].reset_index().drop_duplicates().dropna()\n",
    "ground_truth = ground_truth.sort_values([\"SL BASIN (CODE)\",\"quarter\"])\n",
    "ground_truth = ground_truth.rename(mapper={\"cm\":\"actual_contribution_margin\",\"rev\":\"actual_revenue\"},axis=1)\n",
    "ground_truth = ground_truth.reset_index().drop([\"index\"],axis=1)\n",
    "ground_truth.to_csv('ground_truth.csv')\n",
    "# past dataframes\n",
    "try:\n",
    "    max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "    lr_query = \"\"\"\n",
    "    SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date >= '{}' \n",
    "    \"\"\".format(str(max_date)[-6:])\n",
    "    multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "    multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "    multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\"]]\n",
    "\n",
    "except:\n",
    "    multi_model_df = pd.DataFrame()\n",
    "refresh_date = refresh_date.replace(' ', '') \n",
    "pp = postprocess(refresh_date, cxn_ODS)\n",
    "pp.post_process( train_df, baseline_data_dict,\"RF\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, pr_cm_data_dict,\"Prophet\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, npr_cm_data_dict,\"Neural Prophet\", multi_model_df,ground_truth)\n",
    "\n",
    "\n",
    "\n",
    "model_sel = model_selection(refresh_date,train_basins)\n",
    "try:\n",
    "    best_df = model_sel.best_model(multi_model_df)\n",
    "\n",
    "    best_df.to_sql(con=cxn_ODS, name='cmf3_1_mvp3_Q2_best',if_exists = 'append',index=None)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "lr_query = \"\"\"\n",
    "SELECT * FROM cmf3_1_mvp3_Q2 \n",
    "\"\"\"\n",
    "multi_model_df = pd.read_sql(lr_query,cxn_ODS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b420e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_model_df.to_csv('multi_model_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    max_date = pd.read_sql(\"\"\"SELECT max(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "    lr_query = \"\"\"\n",
    "    SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date >= '{}' \n",
    "    \"\"\".format(str(max_date)[-6:])\n",
    "    multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "    multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "    multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\"]]\n",
    "\n",
    "except:\n",
    "    multi_model_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df[multi_model_df['SL BASIN (CODE)']=='AML-WEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55930b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = baseline_data_dict.copy()\n",
    "model = 'RF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data_dict[baseline_data_dict['SL BASIN (CODE)']=='AML-WEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43901692",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[data_dict['SL BASIN (CODE)']=='AML-WEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2febdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[\"model\"] = model\n",
    "columns_out = [\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\"]\n",
    "\n",
    "multi_model_df = multi_model_df.append(data_dict[columns_out])\n",
    "\n",
    "multi_model_df = multi_model_df.reset_index().drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc964ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df[multi_model_df['SL BASIN (CODE)']=='AML-WEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = multi_model_df.merge(ground_truth,on=[\"quarter\",\"SL BASIN (CODE)\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a['SL BASIN (CODE)']=='AML-WEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b1853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c671f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 19 12:34:21 2023\n",
    "\n",
    "@author: BGondaliya\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil.parser as dparser\n",
    "\n",
    "class postprocess:\n",
    "    def __init__(self,refresh_date, cxn_ODS):\n",
    "        self.refresh_date = refresh_date\n",
    "        self.cxn_ODS = cxn_ODS\n",
    "        \n",
    "    def post_process(self, train_df, data_dict, model, multi_model_df, ground_truth):\n",
    "        data_dict[\"model\"] = model\n",
    "        columns_out = [\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\"]\n",
    "        \n",
    "\n",
    "        multi_model_df = multi_model_df.append(data_dict[columns_out])\n",
    "\n",
    "        multi_model_df = multi_model_df.reset_index().drop([\"index\"],axis=1)\n",
    "       # multi_model_df['quarter'] = pd.to_datetime(multi_model_df['quarter'])\n",
    "        multi_model_df = multi_model_df.merge(ground_truth,on=[\"quarter\",\"SL BASIN (CODE)\"],how=\"left\")\n",
    "        multi_model_df[\"contribution_margin_error\"] = np.round(((multi_model_df[\"cm\"]-multi_model_df[\"actual_contribution_margin\"])/multi_model_df[\"actual_contribution_margin\"]),2)*100\n",
    "        multi_model_df[\"revenue_error\"] = np.round(((multi_model_df[\"rev\"]-multi_model_df[\"actual_revenue\"])/multi_model_df[\"actual_revenue\"]),2)*100\n",
    "        multi_model_df[\"YM\"] = list(map(lambda x: dparser.parse(str(x),fuzzy=True).strftime('%b\\'%y'), multi_model_df[\"quarter\"]))\n",
    "        multi_model_df[\"refresh_date\"] = self.refresh_date\n",
    "        multi_model_df[\"level\"] = multi_model_df[\"SL BASIN (CODE)\"]\n",
    "        multi_model_df = multi_model_df.round(2) \n",
    "\n",
    "\n",
    "        multi_model_df[multi_model_df[\"SL BASIN (CODE)\"]==\"Worldwide\"].sort_values([\"SL BASIN (CODE)\",\"quarter\",\"model\"]).dropna()\n",
    "        multi_model_df = multi_model_df.drop_duplicates()\n",
    "        multi_model_df.to_sql(con=self.cxn_ODS, name='cmf3_1_mvp3_Q2',if_exists = 'append',index=None)\n",
    "       # print(\" Written for Model - {}\".format(, model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59e8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18af98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_date = refresh_date.replace(' ', '') \n",
    "pp = postprocess(refresh_date, cxn_ODS)\n",
    "pp.post_process( train_df, baseline_data_dict,\"RF\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, pr_cm_data_dict,\"Prophet\", multi_model_df,ground_truth)\n",
    "#     pp.post_process( train_df, npr_cm_data_dict,\"Neural Prophet\", multi_model_df,ground_truth)\n",
    "\n",
    "\n",
    "\n",
    "model_sel = model_selection(refresh_date,train_basins)\n",
    "try:\n",
    "    best_df = model_sel.best_model(multi_model_df)\n",
    "\n",
    "    best_df.to_sql(con=cxn_ODS, name='cmf3_1_mvp3_Q2_best',if_exists = 'append',index=None)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dfa586",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date = refresh_date\n",
    "refresh_date = str(pd.to_datetime(refresh_date).replace(day=1)) \n",
    "\n",
    "cutoff_date = pd.to_datetime(refresh_date) + relativedelta(months=-12)\n",
    "cutoff_date = cutoff_date.strftime('%YQ{}'.format( (cutoff_date.month - 1) // 3 + 1))\n",
    "train_basins = train_basins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a27fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    max_date = pd.read_sql(\"\"\"SELECT min(refresh_date) FROM cmf3_1_mvp3_Q2\"\"\",cxn_ODS)\n",
    "#         max_date = pd.to_datetime(max_date[\"max(refresh_date)\"][0],format=\"%Y-%m-%d\")\n",
    "    lr_query = \"\"\"\n",
    "    SELECT * FROM cmf3_1_mvp3_Q2 WHERE refresh_date <= '{}' \n",
    "    \"\"\".format(str(max_date)[-6:])\n",
    "    multi_model_df = pd.read_sql(lr_query,cxn_ODS)\n",
    "#     multi_model_df = multi_model_df[multi_model_df[\"quarter\"]<forecast_start_date]\n",
    "    multi_model_df = multi_model_df[[\"quarter\",\"SL BASIN (CODE)\",\"cm\",\"rev\",\"model\"]]\n",
    "\n",
    "except:\n",
    "    multi_model_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84ca0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cutoff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a23ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.cutoff_date = pd.to_datetime(cutoff_date, format=\"%Y-%m-%d\")\n",
    "self.cutoff_date = cutoff_date.strftime('%Y Q{}'.format( (cutoff_date.month - 1) // 3 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db16110",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86582b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = multi_model_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a787008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = X[X['refresh_date']== ref_date]\n",
    "data = X[(X['quarter'] > cutoff_date) & (X['quarter'] < refresh_date)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47183d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  6 11:17:50 2023\n",
    "\n",
    "@author: BGondaliya\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "class model_selection:\n",
    "    def __init__(self,refresh_date,train_basins):\n",
    "        self.ref_date = refresh_date\n",
    "        self.refresh_date = str(pd.to_datetime(refresh_date).replace(day=1)) #str(date.today(\n",
    "        self.cutoff_date = str(pd.to_datetime(refresh_date) + relativedelta(months=-4))\n",
    "        self.train_basins = train_basins\n",
    "\n",
    "    \n",
    "    def best_model(self, X):\n",
    "        data = X[X['refresh_date']== self.ref_date]\n",
    "        data = data[(data['quarter'] > self.cutoff_date) & (data['quarter'] < self.ref_date)]\n",
    "\n",
    "        data['abs_rev_error'] = abs(data['revenue_error'])\n",
    "        data['abs_cm_error'] = abs(data['contribution_margin_error'])\n",
    "        \n",
    "        grouped_df = data.groupby(['SL BASIN (CODE)', 'model','refresh_date']).agg({'abs_rev_error': 'mean', 'abs_cm_error': 'mean'})\n",
    "        grouped_df = grouped_df.dropna()\n",
    "        \n",
    "        grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "        min_indices = grouped['abs_rev_error'].idxmin()\n",
    "        best_rev_df = grouped_df.loc[min_indices]\n",
    "        \n",
    "        grouped = grouped_df.groupby('SL BASIN (CODE)')\n",
    "\n",
    "        min_indices = grouped['abs_cm_error'].idxmin()\n",
    "        best_cm_df = grouped_df.loc[min_indices]\n",
    "        \n",
    "        # to extract dataframe for best model\n",
    "        data = X[X['refresh_date']== self.ref_date]\n",
    "#         data = data[data['refresh_date']==self.refresh_date]\n",
    "        ans = pd.DataFrame(columns=['YEARMONTH', 'SL BASIN (CODE)', 'rev', 'actual_revenue',\n",
    "               'revenue_error', 'YM', 'refresh_date', 'level', 'rev_Model', 'cm',\n",
    "               'actual_contribution_margin', 'contribution_margin_error', 'cm_Model'])   \n",
    "        for basin in self.train_basins:\n",
    "            print(basin)\n",
    "\n",
    "            rev_model = best_rev_df.loc[best_rev_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "            cm_model = best_cm_df.loc[best_cm_df.index.get_level_values('SL BASIN (CODE)') == basin].index.get_level_values('model')\n",
    "\n",
    "            df_rev = data[(data['SL BASIN (CODE)']==basin) &(data['model']==\"RF\")][['YEARMONTH', 'SL BASIN (CODE)', 'rev',\n",
    "                    'actual_revenue','revenue_error', 'YM', 'refresh_date',\n",
    "                   'level']]\n",
    "            df_rev['rev_Model'] = str(rev_model[0])\n",
    "            df_rev = df_rev.drop_duplicates()\n",
    "\n",
    "            df_cm = data[(data['SL BASIN (CODE)']==basin) &(data['model']==\"RF\")][['YEARMONTH', 'SL BASIN (CODE)', 'cm',\n",
    "                   'actual_contribution_margin', \n",
    "                   'contribution_margin_error', ]]\n",
    "            df_cm['cm_Model'] = str(cm_model[0])\n",
    "            df_cm = df_cm.drop_duplicates()\n",
    "\n",
    "            ans = ans.append(pd.merge(df_rev,df_cm, how='left', on = ['YEARMONTH','SL BASIN (CODE)']))\n",
    "\n",
    "        return ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
